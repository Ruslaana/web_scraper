{
    "version": "1.0",
    "document": {
        "id": 6493,
        "title": "Jacob Mchangama: Europa halter langt efter USA og Kina, når det gælder udvikling af kunstig intelligens",
        "content": "Europa halter langt efter USA og Kina, når det gælder udvikling af kunstig intelligens. Alligevel har EU vedtaget enforordning om harmonisering af kunstig intelligens, der i Bruxelles fejres som »verdens første omfattende AI-lov«. Ligesom EUs forordning om digitale tjenester (DSA) – endnu et område, hvor EU er førende i regulering, men håbløst bagud når det gælder innovation – risikerer AI-forordningen dog at medføre alvorlige konsekvenser for ytringsfriheden og adgang til information. På lidt over et år truede Thierry Breton, der indtil for nylig havde ansvar for DSAen, med atlukkeplatforme, blandede online misinformationsammenmed ulovligt indhold,pressede angiveligtDSA-håndhævelsesteamet til at undersøge X og stod over for beskyldninger omudenlandsk indblandingogpolitiseret håndhævelse. Alle disse handlinger skabte betydeligmodstandfra civilsamfundsorganisationer, der advarede om konsekvenserne for fundamentale frihedsrettigheder. De rejser også et afgørende spørgsmål om, hvorvidt brede og vagt definerede krav i AI-forordningen også kan underminere de grundlæggende rettigheder til ytringsfrihed og adgang til information for brugere af AI-platforme. »På lidt over et år truede Thierry Breton (billedet), der indtil for nylig havde ansvar for DSAen, med at lukke platforme, blandede online misinformation sammen med ulovligt indhold, pressede angiveligt DSA-håndhævelsesteamet til at undersøge X og stod over for beskyldninger om udenlandsk indblanding og politiseret håndhævelse,« skriver Jacob Mchangama.Fold sammenLæs mereFoto: Christophe Petit Tesson/Reuters/Ritzau Scanpix. Før EU vedtager formelle standarder kræver forordningen, at Det Europæiske Kontor for Kunstig Intelligens fremmer udviklingen af etadfærdskodeksfor visse AI-modeller – som Open AI's GPT-4o og Googles Gemini – for at hjælpe med at etablere vigtige normer for, hvordan forordningen vil blive implementeret. Men desværre indeholder detførste udkast tiladfærdskodekset ingen omtale af »ytringsfrihed«. Det foreskriver vage definitioner af det uklare begreb »systemisk risiko« og lægger vægt på et teknokratisk sikkerhedsbegreb, der kan underminere ytringsfriheden i AI-æraen. AI-forordningen kræver, at sådanne AI-modeller vurderer og afbøder »systemiske risici«, defineret som alt, hvad der kan have »betydelig indvirkning på EU-markedet på grund af deres omfang eller på grund af faktiske negative virkninger, der med rimelighed kan forudses, for folkesundheden, sikkerheden, den offentlige sikkerhed, de grundlæggende rettigheder eller samfundet som helhed.« Men hvad udgør en »negativ indvirkning på samfundet«? Hvad sker der, når fremme af den offentlige sikkerhed kommer i konflikt med beskyttelse af grundlæggende rettigheder som ytringsfrihed og adgang til information? Skal teknokrater eksempelvis kunne have indflydelse på, hvilke svar AI-modeller skal genere, når det gælder spørgsmål om politik og sundhed? Udkastet til adfærdskodekset giver ikke nogle gode svar. »Kommissionens næstformand med ansvar for værdier og gennemsigtighed, Věra Jourová (billedet), advarede om, at AI-deepfakes ville skabe »en atombombe … der kunne ændre vælgernes præferencer,« skriver Jacob Mchangama.Fold sammenLæs mereFoto: Kenzo Tribouillard/AFP/Ritzau Scanpix. Af de seks systemiske risici, som udbydere af AI-modeller skal afbøde inden 2025, omfatter kodekset »Overtalelse og manipulation«. Definitionen bygger på stærkt subjektive begreber som »overtalelse i stor skala« og »forsimplet viden«, der let vil kunne misbruges af offentlige myndigheder til at presse AI-udbydere til at censurere deres modeller. Lad os ikke glemme, at flerepolitikereogagenturerpromoverede dommedagsfortællinger om, hvordan ai i sig selv ville underminere valget til Europa-Parlamentet i 2024. Kommissionens næstformand med ansvar for værdier og gennemsigtighed, Věra Jourová, advarede om, at AI-deepfakesville skabe»en atombombe … der kunne ændre vælgernes præferencer«. Denne frygt viste sig at væreubegrundet. Kunstig intelligens er – som trykpressen, den personlige computer og internettet – en revolutionerende teknologi, der kan bruges til både godt og skidt. Men ligesom vi opgav forhåndscensur af trykpressen og ikke kræver, at producenter af PC’er eller internetudbydere præventivt skal sikre, at deres produkter og tjenesteydelser kan misbruges til at producere eller fremskaffe ulovligt indhold, bør reguleringen af kunstig intelligens rette sig mod klare og afgrænsede kategorier af risici. Det indebærer ikke ytringer og information, som magthavere ikke bryder sig om. Jacob Mchangama er direktør i tænketanken Justitia ",
        "metadata": {
            "source": "https://www.berlingske.dk/kommentatorer/jacob-mchangama-europa-halter-langt-efter-usa-og-kina-naar-det",
            "image_url": "https://berlingske.bmcdn.dk/media/cache/resolve/image_x_large/image/186/1865028/24846414-debatinterview-med-jacob-mchangama-om-ytringsfrihe.jpg",
            "publication_time": "Fredag d. 06. december 2024, kl. 11.19",
            "author": "Jacob Mchangama",
            "related_links": [],
            "attachments": []
        }
    }
}